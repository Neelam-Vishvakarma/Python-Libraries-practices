{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dive into Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction & Setup\n",
    "\n",
    "Import pandas and create simple Series and DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a Series\n",
    "s = pd.Series([10, 20, 30, 40, 50])\n",
    "print(\"Series:\\n\", s)\n",
    "\n",
    "# Creating a DataFrame from dict\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Salary': [50000, 60000, 70000, 80000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Viewing & Inspecting Data\n",
    "\n",
    "Learn how to quickly inspect data shape, info, and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of df:\", df.shape)  # rows, columns\n",
    "print(\"Columns names:\", df.columns)\n",
    "print(\"Data types:\\n\", df.dtypes)\n",
    "print(\"Info about DataFrame:\\n\")\n",
    "df.info()\n",
    "\n",
    "print(\"Statistical summary:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecting Data\n",
    "\n",
    "Selecting columns, rows, and subsets using labels and positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select single column (Series)\n",
    "print(\"Name column:\\n\", df['Name'])\n",
    "\n",
    "# Select multiple columns (DataFrame)\n",
    "print(\"Name and Salary columns:\\n\", df[['Name', 'Salary']])\n",
    "\n",
    "# Select rows by position (iloc)\n",
    "print(\"First 2 rows:\\n\", df.iloc[:2])\n",
    "\n",
    "# Select rows by label (loc) - works with index labels\n",
    "print(\"Row with index 1:\\n\", df.loc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering Rows\n",
    "\n",
    "Use conditional statements to filter DataFrame rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter where Age > 30\n",
    "print(\"Age > 30:\\n\", df[df['Age'] > 30])\n",
    "\n",
    "# Filter multiple conditions (AND, OR)\n",
    "filtered = df[(df['Age'] > 25) & (df['Salary'] > 60000)]\n",
    "print(\"Age > 25 and Salary > 60000:\\n\", filtered)\n",
    "\n",
    "# Using isin to filter multiple values\n",
    "names = ['Alice', 'David']\n",
    "print(\"Filter Names Alice or David:\\n\", df[df['Name'].isin(names)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adding & Modifying Columns\n",
    "\n",
    "Create new columns or modify existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column based on existing ones\n",
    "df['Tax'] = df['Salary'] * 0.1\n",
    "print(\"Added Tax column:\\n\", df)\n",
    "\n",
    "# Modify column values\n",
    "df['Salary'] = df['Salary'] + 5000  # increase salary by 5000\n",
    "print(\"Increased Salary:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Handling Missing Data\n",
    "\n",
    "Detect, fill, and drop missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with missing values\n",
    "data_nan = {\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': [5, np.nan, np.nan, 8],\n",
    "    'C': ['a', 'b', 'c', 'd']\n",
    "}\n",
    "df_nan = pd.DataFrame(data_nan)\n",
    "print(\"Data with NaNs:\\n\", df_nan)\n",
    "\n",
    "# Detect missing values\n",
    "print(\"Is null:\\n\", df_nan.isnull())\n",
    "\n",
    "# Drop rows with any NaN\n",
    "print(\"Drop rows with NaN:\\n\", df_nan.dropna())\n",
    "\n",
    "# Fill NaNs with a value\n",
    "print(\"Fill NaN with 0:\\n\", df_nan.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Grouping and Aggregations\n",
    "\n",
    "Group data and calculate aggregates like mean, sum, count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Department': ['Sales', 'Sales', 'IT', 'IT', 'HR', 'HR'],\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'Salary': [50000, 60000, 70000, 80000, 40000, 45000]\n",
    "}\n",
    "df_group = pd.DataFrame(data)\n",
    "\n",
    "# Group by Department and calculate mean salary\n",
    "print(\"Mean salary by department:\\n\", df_group.groupby('Department')['Salary'].mean())\n",
    "\n",
    "# Multiple aggregations\n",
    "print(\"Multiple aggregates:\\n\", df_group.groupby('Department').agg({'Salary': ['mean', 'sum', 'count']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sorting Data\n",
    "\n",
    "Sort by columns ascending/descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Salary descending\n",
    "print(\"Sorted by Salary descending:\\n\", df_group.sort_values(by='Salary', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Working with Dates\n",
    "\n",
    "Convert strings to datetime and extract date components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_data = {\n",
    "    'OrderID': [1, 2, 3],\n",
    "    'OrderDate': ['2021-01-01', '2021-06-15', '2021-12-31']\n",
    "}\n",
    "df_dates = pd.DataFrame(date_data)\n",
    "print(\"Original DataFrame:\\n\", df_dates)\n",
    "\n",
    "# Convert to datetime\n",
    "df_dates['OrderDate'] = pd.to_datetime(df_dates['OrderDate'])\n",
    "print(\"After conversion to datetime:\\n\", df_dates)\n",
    "\n",
    "# Extract year, month, day\n",
    "df_dates['Year'] = df_dates['OrderDate'].dt.year\n",
    "df_dates['Month'] = df_dates['OrderDate'].dt.month\n",
    "df_dates['Day'] = df_dates['OrderDate'].dt.day\n",
    "print(\"Extracted date components:\\n\", df_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Merging and Joining DataFrames\n",
    "\n",
    "Combine data from multiple DataFrames using merge and join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Dept': ['Sales', 'IT', 'HR']\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    'Employee': ['Alice', 'Bob', 'David'],\n",
    "    'Salary': [50000, 60000, 70000]\n",
    "})\n",
    "\n",
    "# Inner join on Employee\n",
    "merged = pd.merge(df1, df2, on='Employee', how='inner')\n",
    "print(\"Inner Join:\\n\", merged)\n",
    "\n",
    "# Left join\n",
    "left_join = pd.merge(df1, df2, on='Employee', how='left')\n",
    "print(\"Left Join:\\n\", left_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Pivot Tables\n",
    "\n",
    "Summarize data using pivot tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Date': ['2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02'],\n",
    "    'City': ['NY', 'LA', 'NY', 'LA'],\n",
    "    'Sales': [100, 200, 150, 250]\n",
    "}\n",
    "df_pivot = pd.DataFrame(data)\n",
    "pivot_table = df_pivot.pivot_table(index='Date', columns='City', values='Sales', aggfunc='sum')\n",
    "print(\"Pivot Table:\\n\", pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Applying Functions\n",
    "\n",
    "Use `apply()`, `map()`, and vectorized operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function to column\n",
    "df['Salary_K'] = df['Salary'].apply(lambda x: x/1000)\n",
    "print(\"Salary in thousands:\\n\", df)\n",
    "\n",
    "# map on Series\n",
    "mapping = {'Alice': 'A', 'Bob': 'B', 'Charlie': 'C', 'David': 'D'}\n",
    "df['Initial'] = df['Name'].map(mapping)\n",
    "print(\"Mapped initials:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Handling Duplicates\n",
    "\n",
    "Detect, drop, and keep duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dup = {\n",
    "    'A': [1, 2, 2, 3, 3, 3],\n",
    "    'B': ['x', 'y', 'y', 'z', 'z', 'z']\n",
    "}\n",
    "df_dup = pd.DataFrame(data_dup)\n",
    "print(\"Original Data with duplicates:\\n\", df_dup)\n",
    "\n",
    "# Find duplicates\n",
    "print(\"Duplicates:\\n\", df_dup.duplicated())\n",
    "\n",
    "# Drop duplicates\n",
    "print(\"After dropping duplicates:\\n\", df_dup.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Exporting Data\n",
    "\n",
    "Save DataFrames to CSV and Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "# Export to Excel\n",
    "df.to_excel('output.xlsx', index=False)\n",
    "\n",
    "print(\"Exported DataFrame to CSV and Excel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Summary:\n",
    "- Created Series and DataFrames\n",
    "- Viewed and selected data\n",
    "- Filtered, added columns, handled missing data\n",
    "- Grouped, merged, and pivoted data\n",
    "- Applied functions, handled duplicates\n",
    "- Exported data\n",
    "\n",
    "This notebook is a solid foundation for working with Pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
